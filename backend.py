import os
import datetime
import webbrowser
import subprocess
import re
from ddgs import DDGS
from llama_cpp import Llama
import memory

# --- C·∫§U H√åNH ---
MODEL_PATH = "models/qwen2.5-3b-instruct-q4_k_m.gguf"

class Colors:
    BLUE = '\033[94m'
    GREEN = '\033[92m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'

class LocalLLM:
    def __init__(self):
        if not os.path.exists(MODEL_PATH):
            raise FileNotFoundError(f"‚ùå Model file not found at: {os.path.abspath(MODEL_PATH)}")
        
        print(f"{Colors.GREEN}Loading model from {MODEL_PATH}...{Colors.ENDC}")
        self.llm = Llama(
            model_path=MODEL_PATH,
            n_gpu_layers=0,
            n_ctx=4096,
            n_threads=6,      
            n_batch=512,
            verbose=False
        )

    # --- H√ÄM TH·ª∞C THI (AGENT) ---
    def execute_command(self, command_str):
        print(f"{Colors.BLUE}[Agent Command] ‚öôÔ∏è {command_str}{Colors.ENDC}")
        try:
            if "YourSearchQueryHere" in command_str:
                webbrowser.open("https://www.google.com")
                return "Link l·ªói, ƒë√£ m·ªü Google."

            if command_str.startswith("OPEN:"):
                url = command_str.replace("OPEN:", "").strip()
                if "youtube.com" in url and "watch" not in url and "search_query" not in url:
                    url = "https://www.youtube.com"
                webbrowser.open(url)
                return f"ƒê√£ m·ªü: {url}"
            
            elif command_str.startswith("APP:"):
                app_name = command_str.replace("APP:", "").strip().lower()
                if "notepad" in app_name: subprocess.Popen("notepad.exe")
                elif "calc" in app_name: subprocess.Popen("calc.exe")
                elif "excel" in app_name: subprocess.Popen("start excel", shell=True)
                elif "word" in app_name: subprocess.Popen("start winword", shell=True)
                elif "code" in app_name: subprocess.Popen("code", shell=True)
                elif "zalo" in app_name: subprocess.Popen(r"C:\Users\admin\AppData\Local\Programs\Zalo\Zalo.exe", shell=True)
                return f"ƒê√£ b·∫≠t ·ª©ng d·ª•ng: {app_name}"
                
        except Exception as e:
            print(f"L·ªói th·ª±c thi: {e}")
            return None
        return None

    def tool_search(self, query):
        print(f"{Colors.BLUE}[Tool] üîç ƒêang tra c·ª©u: {query}{Colors.ENDC}")
        try:
            results = DDGS().text(query, max_results=3)
            if not results: return "Kh√¥ng t√¨m th·∫•y th√¥ng tin."
            summary = ""
            for res in results:
                summary += f"- {res['title']}: {res['body']}\n"
            return summary
        except:
            return "L·ªói k·∫øt n·ªëi m·∫°ng."

    def generate_response(self, messages):
        last_user_msg = next((m['content'] for m in reversed(messages) if m['role'] == 'user'), None)
        context_str = ""
        tool_data = ""
        system_note = "" # D√πng ƒë·ªÉ th√¥ng b√°o cho bot bi·∫øt v·ª´a l∆∞u/x√≥a k√Ω ·ª©c

        if last_user_msg:
            lower_msg = last_user_msg.lower()

            # --- [PH·∫¶N KH√îI PH·ª§C L·∫†I]: QU·∫¢N L√ù K√ù ·ª®C (Memory Management) ---
            
            # 1. L·ªánh QU√äN
            if lower_msg.startswith("qu√™n:") or lower_msg.startswith("forget:"):
                content = last_user_msg.split(":", 1)[1].strip()
                res = memory.delete_similar_memory(content)
                system_note = f"[H·ªÜ TH·ªêNG: {res}]"

            # 2. L·ªánh C·∫¨P NH·∫¨T (Thay ƒë·ªïi)
            elif lower_msg.startswith("thay ƒë·ªïi:") or lower_msg.startswith("c·∫≠p nh·∫≠t:") or lower_msg.startswith("update:"):
                new_content = last_user_msg.split(":", 1)[1].strip()
                # X√≥a c√°i c≈© t∆∞∆°ng t·ª± -> L∆∞u c√°i m·ªõi
                del_res = memory.delete_similar_memory(new_content)
                memory.add_memory(new_content)
                system_note = f"[H·ªÜ TH·ªêNG: ƒê√£ c·∫≠p nh·∫≠t. {del_res}. V√† ƒë√£ l∆∞u th√¥ng tin m·ªõi: '{new_content}']"

            # 3. L·ªánh H√ÉY NH·ªö
            else:
                is_explicit = lower_msg.startswith("h√£y nh·ªõ:") or lower_msg.startswith("remember:")

                if is_explicit:
                    text_to_save = last_user_msg.split(":", 1)[1].strip()
                    memory.add_memory(text_to_save)
                    system_note = f"[H·ªÜ TH·ªêNG: ƒê√£ l∆∞u v√†o b·ªô nh·ªõ d√†i h·∫°n: '{text_to_save}']"

            # --- K·∫æT TH√öC PH·∫¶N KH√îI PH·ª§C ---

            # 4. RAG Retrieval (L·∫•y k√Ω ·ª©c ra ƒë·ªÉ d√πng)
            context_str = memory.get_relevant_context(last_user_msg)
            
            # 5. Search Tool
            search_triggers = ["t√¨m", "tra", "gi√°", "th·ªùi ti·∫øt", "l√† ai", "d√¢n s·ªë", "s·ª± ki·ªán", "·ªü ƒë√¢u"]
            if any(k in lower_msg for k in search_triggers) and "m·ªü" not in lower_msg:
                search_res = self.tool_search(last_user_msg)
                tool_data = f"\n[D·ªÆ LI·ªÜU T√åM KI·∫æM]:\n{search_res}\n"

        current_time = datetime.datetime.now().strftime("%H:%M %d/%m/%Y")
        
        # --- SYSTEM PROMPT ---
        system_prompt = f"""B·∫°n l√† Tr·ª£ l√Ω ·∫¢o Th√¥ng minh. Th·ªùi gian: {current_time}.

        NHI·ªÜM V·ª§:
        1. [ƒêI·ªÄU KHI·ªÇN]: N·∫øu user b·∫£o "M·ªü/B·∫≠t", h√£y d√πng l·ªánh (t·∫•t c·∫£ ƒë·ªÅu cho d√πng ti·∫øng Vi·ªát):
           - [[OPEN: https://www.youtube.com/results?search_query=...]]
           - [[APP: notepad/calc/excel/code]]
           
        2. [K√ù ·ª®C]: 
           - N·∫øu c√≥ th√¥ng b√°o [H·ªÜ TH·ªêNG: ƒê√£ l∆∞u/x√≥a...], h√£y x√°c nh·∫≠n v·ªõi ng∆∞·ªùi d√πng.
           - S·ª≠ d·ª•ng [K√ù ·ª®C D√ÄI H·∫†N] ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c√° nh√¢n.

        3. [TRA C·ª®U]: D√πng [D·ªÆ LI·ªÜU T√åM KI·∫æM] cho c√¢u h·ªèi th·ª±c t·∫ø.
        """

        full_prompt = f"<|im_start|>system\n{system_prompt}"
        if context_str: full_prompt += f"\n[K√ù ·ª®C D√ÄI H·∫†N]: {context_str}"
        if tool_data: full_prompt += tool_data
        if system_note: full_prompt += f"\n{system_note}" # B∆°m th√¥ng b√°o h·ªá th·ªëng v√†o prompt
        full_prompt += "<|im_end|>\n"

        # Ch·ªâ l·∫•y 4 tin nh·∫Øn g·∫ßn nh·∫•t ƒë·ªÉ bot ƒë·ª° lo·∫°n
        recent_messages = messages[-4:] if len(messages) > 4 else messages
        
        for msg in recent_messages:
            full_prompt += f"<|im_start|>{msg['role']}\n{msg['content']}<|im_end|>\n"
        full_prompt += "<|im_start|>assistant\n"

        # --- STREAM ---
        stream_generator = self.llm(
            full_prompt, max_tokens=1024, stop=["<|im_end|>"], 
            echo=False, temperature=0.6, stream=True
        )

        def smart_stream():
            full_response = ""
            command_executed = False
            for chunk in stream_generator:
                text_chunk = chunk['choices'][0]['text']
                full_response += text_chunk
                
                match = re.search(r"\[\[(.*?)\]\]", full_response)
                if match and not command_executed:
                    self.execute_command(match.group(1))
                    command_executed = True
                    yield "‚úÖ ƒêang th·ª±c hi·ªán... \n"
                    full_response = full_response.replace(match.group(0), "")
                
                if not match: yield text_chunk

        return smart_stream(), context_str